package cn.itcast.up.ml

import org.apache.spark.ml.clustering.{KMeans, KMeansModel}
import org.apache.spark.ml.feature.MinMaxScaler
import org.apache.spark.sql.{DataFrame, SparkSession}

/**
 * Author itcast
 * Date 2019/12/8 11:45
 * Desc 演示使用KMeans对鸢尾花数据集进行聚类
 */
object IrisCluster {
  def main(args: Array[String]): Unit = {
    //1.创建SparkSession
    val spark = SparkSession.builder()
      .appName("IrisDecisionTree")
      .master("local[*]")
      .getOrCreate()
    spark.sparkContext.setLogLevel("WARN")

    import spark.implicits._

    //2.读取libsvm数据
    val data: DataFrame = spark.read.format("libsvm").load("file:///D:\\备课\\用户画像\\资料\\数据集\\iris_kmeans.txt")
    data.show(10,false)
    data.printSchema()
    /*
 +-----+-------------------------------+
|label|features                       |
+-----+-------------------------------+
|1.0  |(4,[0,1,2,3],[5.1,3.5,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[4.9,3.0,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[4.7,3.2,1.3,0.2])|
|1.0  |(4,[0,1,2,3],[4.6,3.1,1.5,0.2])|
|1.0  |(4,[0,1,2,3],[5.0,3.6,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[5.4,3.9,1.7,0.4])|
|1.0  |(4,[0,1,2,3],[4.6,3.4,1.4,0.3])|
|1.0  |(4,[0,1,2,3],[5.0,3.4,1.5,0.2])|
|1.0  |(4,[0,1,2,3],[4.4,2.9,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[4.9,3.1,1.5,0.1])|
+-----+-------------------------------+
only showing top 10 rows

root
 |-- label: double (nullable = true)
 |-- features: vector (nullable = true)
     */

    //3.特征工程
    //通过上面的数据显示可以发现,对于libsvm的数据,已经做好的部分的特征工程,对于标签列已经做了数值化,对于特征已经做了向量化
    //留给我们可以做的还有归一化,归一化可以让模型的收敛效率更高,提升模型的精度...
    val scalerDF: DataFrame = new MinMaxScaler()
      .setInputCol("features")
      .setOutputCol("scalerFeatures")
      .fit(data).transform(data)
    scalerDF.show(10,false)
    /*
 +-----+-------------------------------+---------------------------------------------------------------------------------+
|label|features                       |scalerFeatures                                                                   |
+-----+-------------------------------+---------------------------------------------------------------------------------+
|1.0  |(4,[0,1,2,3],[5.1,3.5,1.4,0.2])|[0.22222222222222213,0.6249999999999999,0.06779661016949151,0.04166666666666667] |
|1.0  |(4,[0,1,2,3],[4.9,3.0,1.4,0.2])|[0.1666666666666668,0.41666666666666663,0.06779661016949151,0.04166666666666667] |
|1.0  |(4,[0,1,2,3],[4.7,3.2,1.3,0.2])|[0.11111111111111119,0.5,0.05084745762711865,0.04166666666666667]                |
|1.0  |(4,[0,1,2,3],[4.6,3.1,1.5,0.2])|[0.08333333333333327,0.4583333333333333,0.0847457627118644,0.04166666666666667]  |
|1.0  |(4,[0,1,2,3],[5.0,3.6,1.4,0.2])|[0.19444444444444448,0.6666666666666666,0.06779661016949151,0.04166666666666667] |
|1.0  |(4,[0,1,2,3],[5.4,3.9,1.7,0.4])|[0.30555555555555564,0.7916666666666665,0.11864406779661016,0.12500000000000003] |
|1.0  |(4,[0,1,2,3],[4.6,3.4,1.4,0.3])|[0.08333333333333327,0.5833333333333333,0.06779661016949151,0.08333333333333333] |
|1.0  |(4,[0,1,2,3],[5.0,3.4,1.5,0.2])|[0.19444444444444448,0.5833333333333333,0.0847457627118644,0.04166666666666667]  |
|1.0  |(4,[0,1,2,3],[4.4,2.9,1.4,0.2])|[0.027777777777777922,0.3749999999999999,0.06779661016949151,0.04166666666666667]|
|1.0  |(4,[0,1,2,3],[4.9,3.1,1.5,0.1])|[0.1666666666666668,0.4583333333333333,0.0847457627118644,0.0]                   |
+-----+-------------------------------+---------------------------------------------------------------------------------+
     */

    //4.建立模型并训练
    val model: KMeansModel = new KMeans()
      .setK(3) //设置K值,就是聚为几类
      .setSeed(10) //设置随机种子,觉得初始化聚类中心的位置
      .setMaxIter(10) //最大迭代次数
      .setFeaturesCol("scalerFeatures") //设置特征列,应该是上面归一化之后的列
      .setPredictionCol("predict") //设置预测列,即数据该聚为哪一类
      .fit(scalerDF)

    //5.进行聚类
    val result: DataFrame = model.transform(scalerDF)

    //6.查看结果
    result.show(10,false)
    /*
 +-----+-------------------------------+---------------------------------------------------------------------------------+-------+
|label|features                       |scalerFeatures                                                                   |predict|
+-----+-------------------------------+---------------------------------------------------------------------------------+-------+
|1.0  |(4,[0,1,2,3],[5.1,3.5,1.4,0.2])|[0.22222222222222213,0.6249999999999999,0.06779661016949151,0.04166666666666667] |0      |
|1.0  |(4,[0,1,2,3],[4.9,3.0,1.4,0.2])|[0.1666666666666668,0.41666666666666663,0.06779661016949151,0.04166666666666667] |0      |
|1.0  |(4,[0,1,2,3],[4.7,3.2,1.3,0.2])|[0.11111111111111119,0.5,0.05084745762711865,0.04166666666666667]                |0      |
|1.0  |(4,[0,1,2,3],[4.6,3.1,1.5,0.2])|[0.08333333333333327,0.4583333333333333,0.0847457627118644,0.04166666666666667]  |0      |
|1.0  |(4,[0,1,2,3],[5.0,3.6,1.4,0.2])|[0.19444444444444448,0.6666666666666666,0.06779661016949151,0.04166666666666667] |0      |
|1.0  |(4,[0,1,2,3],[5.4,3.9,1.7,0.4])|[0.30555555555555564,0.7916666666666665,0.11864406779661016,0.12500000000000003] |0      |
|1.0  |(4,[0,1,2,3],[4.6,3.4,1.4,0.3])|[0.08333333333333327,0.5833333333333333,0.06779661016949151,0.08333333333333333] |0      |
|1.0  |(4,[0,1,2,3],[5.0,3.4,1.5,0.2])|[0.19444444444444448,0.5833333333333333,0.0847457627118644,0.04166666666666667]  |0      |
|1.0  |(4,[0,1,2,3],[4.4,2.9,1.4,0.2])|[0.027777777777777922,0.3749999999999999,0.06779661016949151,0.04166666666666667]|0      |
|1.0  |(4,[0,1,2,3],[4.9,3.1,1.5,0.1])|[0.1666666666666668,0.4583333333333333,0.0847457627118644,0.0]                   |0      |
+-----+-------------------------------+---------------------------------------------------------------------------------+-------+
     */

    result.groupBy('label,'predict).count().show()
    /*
 +-----+-------+-----+
|label|predict|count|
+-----+-------+-----+
|  2.0|      1|   47|
|  1.0|      0|   50|
|  2.0|      2|    3|
|  3.0|      1|   14|
|  3.0|      2|   36|
+-----+-------+-----+
     */

  }
}
